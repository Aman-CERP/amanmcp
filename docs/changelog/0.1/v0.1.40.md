# v0.1.40 - 2026-01-04

## Bug Fixing Sprint: Index Integrity & File Watching

This release fixes 7 bugs discovered during code audit of index update/removal and gitignore handling.

---

## Fixed

### HIGH Priority

- **BUG-022**: Scanner gitignore cache now invalidated on .gitignore changes
- **BUG-023**: Use best-effort delete pattern (metadata is source of truth, orphans filtered at search)

### MEDIUM Priority

- **BUG-025**: Add RLock to shouldIgnore functions to prevent gitignore reload race
- **BUG-026**: Log warning when deleting orphan file records fails
- **BUG-027**: Detect .amanmcp.yaml config changes and trigger reconciliation

### LOW Priority

- **BUG-029**: Log warnings for nested gitignore permission/read errors
- **BUG-031**: Log debug when DeleteChunks row count doesn't match expected

---

## Added

- Add OllamaEmbedder for Ollama API-based neural embeddings (recommended for quality)
- Add `AMANMCP_EMBEDDER=ollama` environment variable to select Ollama provider
- Add `AMANMCP_OLLAMA_HOST` environment variable for custom Ollama endpoint
- Add `AMANMCP_OLLAMA_TIMEOUT` environment variable to configure HTTP request timeout
- Add support for qwen3-embedding, nomic-embed-text, nomic-embed-code models
- Add auto-detection of embedding dimensions from Ollama model
- Add native batch embedding via Ollama /api/embed endpoint
- Add graceful fallback chain: Ollama → Yzma → Static
- Add `UseGPU` config option to LlamaConfig for GPU control
- Add `runtime.LockOSThread()` protection for Metal GPU operations
- Add `AMANMCP_USE_LLAMA=1` environment variable to force LlamaEmbedder
- Add YzmaEmbedder using hybridgroup/yzma v1.4.0 (alternative to gollama.cpp)
- Add `AMANMCP_EMBEDDER=yzma` environment variable to select embedder
- Add `OpConfigChange` operation type for config file change detection

---

## Changed

- Increase default Ollama timeout from 30s to 60s to handle large batch embeddings
- Default to static embedder (768 dims) due to llama.cpp Metal instability (BUG-021)
- LlamaEmbedder now opt-in via `AMANMCP_USE_LLAMA=1` until upstream fix
- YzmaEmbedder defaults to CPU-only (UseGPU: false) due to same Metal crash

---

## Removed

- Remove gollama.cpp embedder (replaced by yzma, both affected by llama.cpp Metal bug #18568)

---

## Documentation

- Add BUG-021 documentation (indexer SIGBUS crash during embedding)
- Update BUG-021 with root cause: llama.cpp Metal bug affects ALL Go bindings
- File upstream issue: [llama.cpp#18568](https://github.com/ggml-org/llama.cpp/issues/18568)
- Update dogfooding log with Entry 007 (v0.1.39 validation blocked)
- Update dogfooding log with Entry 008 (search quality observation)
- Update bug tracker with BUG-021 (Critical, High priority)
- Add RCA-006: CGO Dependency Removal postmortem
- Add ADR-023: Ollama HTTP API Embedder Re-introduction
- Add F30: Ollama HTTP API Embedder feature specification
- Add F30-validation.md: Validation guide for Ollama embedder
- Comprehensive audit of index update/removal and gitignore handling (BUG-022 to BUG-031)

---

## Commits

- `0d5fec5` fix(search): BUG-023 best-effort delete pattern
- `0b3248b` fix: BUG-026, BUG-029, BUG-031 logging improvements
- `5b98825` fix(watcher): BUG-025 RWMutex for gitignore matcher
- `9916f9a` fix(watcher): BUG-027 detect and handle config file changes

---

## Known Issues

- **BUG-021**: llama.cpp Metal SIGBUS crash - workaround: use static/ollama embedder
- **BUG-024**: HNSW unbounded growth from lazy deletion (deferred - requires library changes)
- **BUG-028**: Full rescan on gitignore change (deferred - correctness OK)
- **BUG-030**: Event buffer overflow drops events (deferred - rare edge case)
